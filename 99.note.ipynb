{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dd91d-aa60-407a-9019-05b138a57c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run animegan2\n",
    "# data:Hayao, Paprika, Shinkai, SummerWar\n",
    "\n",
    "!pip install nvidia-pyindex\n",
    "!pip install nvidia-tensorflow[horovod]\n",
    "!conda install -c conda-forge openmpi\n",
    "\n",
    "!git clone https://github.com/TachibanaYoshino/AnimeGANv2\n",
    "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/dataset-1/dataset.zip\n",
    "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/vgg16%2F19.npy/vgg19.npy\n",
    "!cp -f vgg19.npy AnimeGANv2/vgg19_weight/vgg19.npy\n",
    "!unzip \"dataset.zip\" -d \"AnimeGANv2/dataset/\"\n",
    "\n",
    "!python train.py --dataset Hayao --epoch 101 --init_epoch 10\n",
    "!python test.py --checkpoint_dir checkpoint/generator_Hayao_weight --test_dir dataset/test/HR_photo --save_dir Hayao/HR_photo\n",
    "!tensorboard --bind_all --logdir checkpoint/generator_Hayao_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7715a914-1668-4e12-8221-1a66c358a3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1 features.0.weight\n",
      "conv1_1 features.0.bias\n",
      "conv1_2 features.2.weight\n",
      "conv1_2 features.2.bias\n",
      "conv2_1 features.5.weight\n",
      "conv2_1 features.5.bias\n",
      "conv2_2 features.7.weight\n",
      "conv2_2 features.7.bias\n",
      "conv3_1 features.10.weight\n",
      "conv3_1 features.10.bias\n",
      "conv3_2 features.12.weight\n",
      "conv3_2 features.12.bias\n",
      "conv3_3 features.14.weight\n",
      "conv3_3 features.14.bias\n",
      "conv3_4 features.16.weight\n",
      "conv3_4 features.16.bias\n",
      "conv4_1 features.19.weight\n",
      "conv4_1 features.19.bias\n",
      "conv4_2 features.21.weight\n",
      "conv4_2 features.21.bias\n",
      "conv4_3 features.23.weight\n",
      "conv4_3 features.23.bias\n",
      "conv4_4 features.25.weight\n",
      "conv4_4 features.25.bias\n",
      "conv5_1 features.28.weight\n",
      "conv5_1 features.28.bias\n",
      "conv5_2 features.30.weight\n",
      "conv5_2 features.30.bias\n",
      "conv5_3 features.32.weight\n",
      "conv5_3 features.32.bias\n",
      "conv5_4 features.34.weight\n",
      "conv5_4 features.34.bias\n",
      "fc6 classifier.0.weight\n",
      "fc6 classifier.0.bias\n",
      "fc7 classifier.3.weight\n",
      "fc7 classifier.3.bias\n",
      "fc8 classifier.6.weight\n",
      "fc8 classifier.6.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load animegan vgg19 as torch vgg\n",
    "# animegan vgg: bgr and 255\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "vgg19_255 = np.load(\"vgg19.npy\", encoding=\"latin1\", allow_pickle=True).item()\n",
    "vgg19_255_keys = list(vgg19_255.keys())\n",
    "vgg19_255_keys.sort()\n",
    "\n",
    "vgg19 = models.vgg19()\n",
    "vgg19_state_dict = vgg19.state_dict()\n",
    "\n",
    "for i, key in enumerate(vgg19_state_dict):\n",
    "    print(vgg19_255_keys[i // 2], key)\n",
    "    weight = vgg19_255[vgg19_255_keys[i // 2]]\n",
    "    weight = weight[0] if \"weight\" in key else weight[1]\n",
    "\n",
    "    if \"bias\" in key:\n",
    "        pass\n",
    "    elif \"features\" in key:\n",
    "        weight = np.transpose(weight, (3, 2, 0, 1))\n",
    "    elif \"classifier\" in key:\n",
    "        weight = np.transpose(weight, (1, 0))\n",
    "    vgg19_state_dict[key] = torch.from_numpy(weight)\n",
    "\n",
    "vgg19.load_state_dict(vgg19_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45612fd6-c438-4262-8c33-5067eff29735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unet\n",
    "# learn_gen = unet_learner(dls, resnet34, loss_func=F.l1_loss, blur=True, norm_type=NormType.Weight, self_attention=True, y_range=(-3.0, 3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e02fb0bf-1d6d-4d5a-a707-8be263f8a973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import Generator\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = Generator().to(device)\n",
    "model.load_state_dict(torch.load(\"test.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
